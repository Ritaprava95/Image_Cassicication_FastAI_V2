{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e4fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys, os, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2e061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "learner = load_learner(r\"..\\model\\vision_classifier_model\", cpu=False) #we want to run predictions on GPU sp cpu=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc0aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pytorch dataloader data\n",
    "fastai_vision_classifier_data = torch.load(r\"..\\fastai_data\\fastai_vision_classifier_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd529b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adho mukha svanasana', 'adho mukha vriksasana', 'agnistambhasana', 'ananda balasana', 'anantasana', 'anjaneyasana', 'ardha bhekasana', 'ardha chandrasana', 'ardha matsyendrasana', 'ardha pincha mayurasana', 'ardha uttanasana', 'ashtanga namaskara', 'astavakrasana', 'baddha konasana', 'bakasana', 'balasana', 'bhairavasana', 'bharadvajasana i', 'bhekasana', 'bhujangasana', 'bhujapidasana', 'bitilasana', 'camatkarasana', 'chakravakasana', 'chaturanga dandasana', 'dandasana', 'dhanurasana', 'durvasasana', 'dwi pada viparita dandasana', 'eka pada koundinyanasana i', 'eka pada koundinyanasana ii', 'eka pada rajakapotasana', 'eka pada rajakapotasana ii', 'ganda bherundasana', 'garbha pindasana', 'garudasana', 'gomukhasana', 'halasana', 'hanumanasana', 'janu sirsasana', 'kapotasana', 'krounchasana', 'kurmasana', 'lolasana', 'makara adho mukha svanasana', 'makarasana', 'malasana', 'marichyasana i', 'marichyasana iii', 'marjaryasana', 'matsyasana', 'mayurasana', 'natarajasana', 'padangusthasana', 'padmasana', 'parighasana', 'paripurna navasana', 'parivrtta janu sirsasana', 'parivrtta parsvakonasana', 'parivrtta trikonasana', 'parsva bakasana', 'parsvottanasana', 'pasasana', 'paschimottanasana', 'phalakasana', 'pincha mayurasana', 'prasarita padottanasana', 'purvottanasana', 'salabhasana', 'salamba bhujangasana', 'salamba sarvangasana', 'salamba sirsasana', 'savasana', 'setu bandha sarvangasana', 'simhasana', 'sukhasana', 'supta baddha konasana', 'supta matsyendrasana', 'supta padangusthasana', 'supta virasana', 'tadasana', 'tittibhasana', 'tolasana', 'tulasana', 'upavistha konasana', 'urdhva dhanurasana', 'urdhva hastasana', 'urdhva mukha svanasana', 'urdhva prasarita eka padasana', 'ustrasana', 'utkatasana', 'uttana shishosana', 'uttanasana', 'utthita ashwa sanchalanasana', 'utthita hasta padangustasana', 'utthita parsvakonasana', 'utthita trikonasana', 'vajrasana', 'vasisthasana', 'viparita karani', 'virabhadrasana i', 'virabhadrasana ii', 'virabhadrasana iii', 'virasana', 'vriksasana', 'vrischikasana', 'yoganidrasana']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the order in which classes are present \n",
    "# so when we get probabilities for a single image, they represents probabilities of these class in this order\n",
    "fastai_vision_classifier_data.categorize.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba57e60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phalakasana\\46-0.png</td>\n",
       "      <td>phalakasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parsvottanasana\\69-0.png</td>\n",
       "      <td>parsvottanasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adho mukha vriksasana\\62-0.png</td>\n",
       "      <td>adho mukha vriksasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eka pada koundinyanasana ii\\9-0.png</td>\n",
       "      <td>eka pada koundinyanasana ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhujangasana\\56-0.png</td>\n",
       "      <td>bhujangasana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_name                        label\n",
       "0                 phalakasana\\46-0.png                  phalakasana\n",
       "1             parsvottanasana\\69-0.png              parsvottanasana\n",
       "2       adho mukha vriksasana\\62-0.png        adho mukha vriksasana\n",
       "3  eka pada koundinyanasana ii\\9-0.png  eka pada koundinyanasana ii\n",
       "4                bhujangasana\\56-0.png                 bhujangasana"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading train and test data\n",
    "train_df = pd.read_csv(r\"..\\train_data.csv\")\n",
    "test_df = pd.read_csv(r\"..\\test_data.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1deccb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add image path column to perform prediction\n",
    "base_path = r\"E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\"\n",
    "\n",
    "train_df['image_path'] = train_df['image_name'].apply(lambda x: os.path.join(base_path,x))\n",
    "test_df['image_path'] = test_df['image_name'].apply(lambda x: os.path.join(base_path,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59363049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phalakasana\\46-0.png</td>\n",
       "      <td>phalakasana</td>\n",
       "      <td>E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\phalakasana\\46-0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parsvottanasana\\69-0.png</td>\n",
       "      <td>parsvottanasana</td>\n",
       "      <td>E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\parsvottanasana\\69-0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adho mukha vriksasana\\62-0.png</td>\n",
       "      <td>adho mukha vriksasana</td>\n",
       "      <td>E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\adho mukha vriksasana\\62-0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eka pada koundinyanasana ii\\9-0.png</td>\n",
       "      <td>eka pada koundinyanasana ii</td>\n",
       "      <td>E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\eka pada koundinyanasana ii\\9-0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhujangasana\\56-0.png</td>\n",
       "      <td>bhujangasana</td>\n",
       "      <td>E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\bhujangasana\\56-0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_name                        label  \\\n",
       "0                 phalakasana\\46-0.png                  phalakasana   \n",
       "1             parsvottanasana\\69-0.png              parsvottanasana   \n",
       "2       adho mukha vriksasana\\62-0.png        adho mukha vriksasana   \n",
       "3  eka pada koundinyanasana ii\\9-0.png  eka pada koundinyanasana ii   \n",
       "4                bhujangasana\\56-0.png                 bhujangasana   \n",
       "\n",
       "                                                                                                 image_path  \n",
       "0                 E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\phalakasana\\46-0.png  \n",
       "1             E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\parsvottanasana\\69-0.png  \n",
       "2       E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\adho mukha vriksasana\\62-0.png  \n",
       "3  E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\eka pada koundinyanasana ii\\9-0.png  \n",
       "4                E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\bhujangasana\\56-0.png  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefca31e",
   "metadata": {},
   "source": [
    "## Probability predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946baaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritap\\anaconda3\\envs\\fastaiv2\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorBase([[1.2136e-06, 2.1741e-06, 2.2942e-06,  ..., 7.0912e-06,\n",
       "              7.4255e-07, 1.5713e-06],\n",
       "             [1.3721e-04, 1.9494e-08, 5.2073e-09,  ..., 1.1977e-09,\n",
       "              8.0582e-09, 3.2711e-09],\n",
       "             [2.6776e-05, 3.8056e-02, 1.8949e-05,  ..., 5.4684e-07,\n",
       "              3.1409e-04, 6.4775e-06],\n",
       "             ...,\n",
       "             [3.6749e-07, 3.9880e-05, 1.6397e-06,  ..., 7.3949e-08,\n",
       "              9.8613e-07, 2.0675e-08],\n",
       "             [8.6332e-08, 7.5092e-09, 1.6425e-11,  ..., 5.1331e-12,\n",
       "              3.0085e-11, 5.0214e-14],\n",
       "             [2.0292e-05, 4.6050e-07, 3.4594e-04,  ..., 1.2893e-04,\n",
       "              9.1153e-08, 1.7002e-06]]),\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "train_dl = learner.dls.test_dl(train_df['image_path'])\n",
    "train_pred_proba = learner.get_preds(dl=train_dl)\n",
    "train_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef40432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of probabilities per image: 107,\n",
      " TensorBase([1.2126e-06, 2.1477e-04, 1.9857e-01, 3.3747e-05, 2.2088e-04,\n",
      "            7.8194e-06, 2.4866e-05, 9.6630e-06, 4.9474e-04, 4.6295e-06,\n",
      "            2.0160e-05, 1.3060e-05, 7.5531e-06, 4.1833e-05, 8.3155e-07,\n",
      "            1.1463e-04, 2.0731e-05, 5.3838e-01, 5.9509e-05, 1.5125e-04,\n",
      "            5.9372e-07, 7.2116e-06, 2.2432e-06, 9.1113e-05, 1.0324e-04,\n",
      "            2.1562e-02, 4.0361e-06, 4.4596e-05, 6.0879e-06, 5.0423e-06,\n",
      "            5.1854e-06, 4.8424e-05, 3.6546e-05, 5.7057e-06, 1.6246e-05,\n",
      "            1.1009e-04, 2.5379e-03, 4.7844e-04, 6.4381e-06, 1.7833e-05,\n",
      "            2.0290e-05, 1.2633e-03, 3.7688e-05, 3.4989e-05, 1.3366e-03,\n",
      "            3.3615e-04, 1.3891e-04, 3.5954e-05, 4.5017e-04, 1.9762e-06,\n",
      "            2.1981e-04, 6.0994e-06, 1.6776e-05, 4.0458e-04, 7.6285e-03,\n",
      "            3.2240e-05, 1.3569e-06, 5.0872e-06, 1.6445e-06, 7.1106e-05,\n",
      "            5.6268e-06, 6.6850e-06, 4.2311e-05, 1.0967e-05, 2.7842e-05,\n",
      "            1.1430e-04, 1.8079e-04, 1.4165e-05, 9.2278e-05, 7.8927e-03,\n",
      "            2.4624e-02, 1.0756e-04, 1.0242e-03, 1.0308e-05, 3.1857e-02,\n",
      "            4.1887e-03, 1.0588e-05, 2.5686e-05, 3.1795e-04, 1.1380e-03,\n",
      "            1.6977e-02, 4.2700e-06, 1.2021e-04, 2.1201e-03, 6.5066e-05,\n",
      "            5.2682e-06, 3.0796e-04, 1.1417e-05, 1.5407e-05, 3.6574e-03,\n",
      "            1.6190e-05, 6.8621e-06, 1.6868e-05, 2.9106e-05, 4.8133e-05,\n",
      "            6.0862e-06, 2.2327e-05, 2.3698e-02, 1.9130e-06, 2.5821e-03,\n",
      "            7.9297e-05, 1.1631e-04, 3.7152e-05, 1.0257e-01, 2.6445e-04,\n",
      "            5.0106e-06, 4.8522e-06])\n"
     ]
    }
   ],
   "source": [
    "# prediction probability for single image\n",
    "# there are 100 probability score for 107 classes (fastai_vision_classifier_data.categorize.vocab will give us the class order see the start of notebook)\n",
    "print(f\"number of probabilities per image: {len(train_pred_proba[0][10])},\\n {train_pred_proba[0][10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9368c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets do the same for test set\n",
    "# make predictions for test set\n",
    "test_dl = learner.dls.test_dl(test_df['image_path'])\n",
    "test_pred_proba = learner.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df447e92",
   "metadata": {},
   "source": [
    "## Class predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2879ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('phalakasana',\n",
       " TensorBase(64),\n",
       " TensorBase([1.2136e-06, 2.1741e-06, 2.2941e-06, 7.4149e-07, 7.1284e-06,\n",
       "             4.1429e-07, 9.7059e-04, 1.0143e-05, 5.5492e-08, 7.9466e-07,\n",
       "             1.2776e-06, 8.7233e-06, 9.2469e-04, 2.4280e-07, 2.4973e-06,\n",
       "             8.3975e-07, 2.8913e-04, 8.7424e-07, 8.6819e-06, 1.9491e-04,\n",
       "             9.1860e-07, 1.8082e-04, 7.9417e-06, 2.9597e-05, 8.1415e-02,\n",
       "             6.7477e-05, 5.5090e-06, 7.4433e-06, 5.3435e-06, 3.6609e-04,\n",
       "             1.9580e-05, 3.2294e-07, 3.5633e-07, 1.8527e-07, 3.3431e-07,\n",
       "             1.1283e-05, 1.0114e-07, 1.4171e-05, 7.9903e-07, 2.1417e-07,\n",
       "             4.8552e-07, 9.0413e-06, 4.9727e-06, 4.0315e-07, 9.0342e-02,\n",
       "             7.7644e-04, 4.1109e-06, 7.4713e-06, 7.0745e-05, 6.9767e-06,\n",
       "             7.9920e-07, 1.5678e-04, 2.3868e-07, 2.9852e-07, 1.9201e-07,\n",
       "             1.5611e-07, 4.8276e-06, 4.8072e-08, 2.0441e-04, 8.3911e-07,\n",
       "             6.7689e-06, 2.3570e-07, 1.0479e-06, 1.1009e-05, 8.0433e-01,\n",
       "             2.2640e-05, 3.0276e-07, 3.1675e-03, 6.5637e-04, 1.2789e-02,\n",
       "             1.8799e-06, 3.0882e-06, 1.1750e-05, 4.2110e-06, 7.5423e-06,\n",
       "             5.6669e-06, 4.8352e-07, 3.4138e-07, 2.7299e-07, 4.1250e-07,\n",
       "             4.9835e-07, 2.0773e-03, 1.7908e-05, 3.1186e-06, 3.9381e-05,\n",
       "             1.4516e-06, 1.5695e-05, 3.2336e-04, 4.3960e-06, 6.8331e-07,\n",
       "             1.9662e-08, 8.8268e-07, 3.5003e-07, 3.0659e-06, 1.3207e-05,\n",
       "             2.4747e-05, 1.6335e-06, 9.0939e-06, 5.4981e-05, 8.5529e-07,\n",
       "             3.2019e-05, 1.3080e-04, 6.5359e-05, 8.7118e-07, 7.0912e-06,\n",
       "             7.4254e-07, 1.5713e-06]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for single image\n",
    "# it returns class with heights probability along with all the class probabilities \n",
    "learner.predict(r\"E:\\Work\\Data_Science\\Projects\\Image_Classification_FastAI_V2\\dataset\\phalakasana\\46-0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f1df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train preds\n",
    "train_preds = train_df['image_path'].apply(lambda img:learner.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b1467c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (phalakasana, TensorBase(64), [TensorBase(1.2136e-06), TensorBase(2.1741e-06), TensorBase(2.2941e-06), TensorBase(7.4149e-07), TensorBase(7.1284e-06), TensorBase(4.1429e-07), TensorBase(0.0010), TensorBase(1.0143e-05), TensorBase(5.5492e-08), TensorBase(7.9466e-07), TensorBase(1.2776e-06), TensorBase(8.7233e-06), TensorBase(0.0009), TensorBase(2.4280e-07), TensorBase(2.4973e-06), TensorBase(8.3975e-07), TensorBase(0.0003), TensorBase(8.7424e-07), TensorBase(8.6819e-06), TensorBase(0.0002), TensorBase(9.1860e-07), TensorBase(0.0002), TensorBase(7.9417e-06), TensorBase(2.9597e-05), TensorBas...\n",
       "1       (parsvottanasana, TensorBase(61), [TensorBase(0.0001), TensorBase(1.9494e-08), TensorBase(5.2073e-09), TensorBase(8.2861e-10), TensorBase(3.5121e-11), TensorBase(7.9187e-07), TensorBase(1.5818e-10), TensorBase(1.3255e-07), TensorBase(1.2740e-07), TensorBase(3.2450e-05), TensorBase(0.0070), TensorBase(1.9228e-08), TensorBase(7.1881e-10), TensorBase(6.2949e-09), TensorBase(4.7704e-06), TensorBase(1.5287e-09), TensorBase(1.1742e-11), TensorBase(9.2453e-09), TensorBase(3.6917e-11), TensorBase(5.8850e-09), TensorBase(6.8090e-07), TensorBase(1.0560e-07), TensorBase(1.0008e-05), TensorBase(1.2981...\n",
       "2       (pincha mayurasana, TensorBase(65), [TensorBase(2.6775e-05), TensorBase(0.0381), TensorBase(1.8949e-05), TensorBase(0.0007), TensorBase(0.0026), TensorBase(0.0003), TensorBase(5.1122e-07), TensorBase(0.0103), TensorBase(3.4030e-06), TensorBase(0.0012), TensorBase(0.0005), TensorBase(1.2381e-06), TensorBase(7.7280e-06), TensorBase(1.1131e-05), TensorBase(1.5952e-05), TensorBase(0.0002), TensorBase(1.0651e-05), TensorBase(2.0380e-05), TensorBase(1.9634e-05), TensorBase(0.0001), TensorBase(1.4032e-05), TensorBase(1.5919e-05), TensorBase(1.0060e-05), TensorBase(2.3419e-05), TensorBase(7.3954e-...\n",
       "3       (eka pada koundinyanasana ii, TensorBase(30), [TensorBase(1.1159e-07), TensorBase(6.8942e-05), TensorBase(1.0112e-07), TensorBase(5.4971e-08), TensorBase(2.2309e-06), TensorBase(4.8576e-07), TensorBase(4.1986e-06), TensorBase(1.4107e-05), TensorBase(2.9156e-08), TensorBase(6.2172e-05), TensorBase(6.1559e-07), TensorBase(0.0004), TensorBase(0.0023), TensorBase(3.5522e-06), TensorBase(3.3273e-05), TensorBase(2.7111e-07), TensorBase(1.6188e-05), TensorBase(5.7826e-08), TensorBase(1.0169e-05), TensorBase(1.0577e-07), TensorBase(2.1093e-06), TensorBase(1.0464e-06), TensorBase(6.4572e-06), Tenso...\n",
       "4       (bhujangasana, TensorBase(19), [TensorBase(6.4209e-05), TensorBase(1.5531e-07), TensorBase(2.2224e-06), TensorBase(3.1585e-05), TensorBase(1.2258e-05), TensorBase(0.0002), TensorBase(0.0006), TensorBase(1.0069e-06), TensorBase(7.5847e-05), TensorBase(6.0457e-05), TensorBase(6.3467e-07), TensorBase(7.9724e-06), TensorBase(8.6882e-07), TensorBase(4.0601e-07), TensorBase(1.2153e-06), TensorBase(1.5917e-05), TensorBase(9.7183e-06), TensorBase(1.2074e-05), TensorBase(5.7863e-06), TensorBase(0.9448), TensorBase(4.7079e-07), TensorBase(0.0001), TensorBase(7.9540e-06), TensorBase(2.9696e-05), Tens...\n",
       "                                                                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                                                                           \n",
       "4790    (astavakrasana, TensorBase(12), [TensorBase(1.2338e-07), TensorBase(4.8385e-06), TensorBase(1.5006e-07), TensorBase(1.1204e-07), TensorBase(7.5624e-07), TensorBase(3.6688e-08), TensorBase(8.1358e-06), TensorBase(5.8575e-07), TensorBase(2.8337e-07), TensorBase(2.3160e-05), TensorBase(7.2067e-08), TensorBase(5.3776e-05), TensorBase(0.9187), TensorBase(1.3678e-05), TensorBase(0.0001), TensorBase(1.0668e-07), TensorBase(6.0038e-05), TensorBase(7.1343e-08), TensorBase(1.0586e-06), TensorBase(1.0080e-08), TensorBase(1.6895e-05), TensorBase(6.8889e-08), TensorBase(6.7016e-05), TensorBase(4.1697e-...\n",
       "4791    (salamba sarvangasana, TensorBase(70), [TensorBase(2.7257e-07), TensorBase(0.0003), TensorBase(0.0001), TensorBase(4.5826e-06), TensorBase(0.0004), TensorBase(1.9075e-06), TensorBase(1.4996e-08), TensorBase(1.6347e-05), TensorBase(1.0381e-06), TensorBase(1.4217e-05), TensorBase(3.5359e-05), TensorBase(2.5713e-07), TensorBase(5.3791e-08), TensorBase(5.6142e-07), TensorBase(7.0508e-08), TensorBase(0.0002), TensorBase(4.2234e-07), TensorBase(0.0002), TensorBase(6.1278e-06), TensorBase(2.7365e-05), TensorBase(1.5993e-07), TensorBase(4.2183e-07), TensorBase(2.2564e-07), TensorBase(2.7928e-06), ...\n",
       "4792    (uttanasana, TensorBase(92), [TensorBase(3.6749e-07), TensorBase(3.9880e-05), TensorBase(1.6397e-06), TensorBase(6.8554e-07), TensorBase(9.8095e-09), TensorBase(1.0394e-07), TensorBase(2.3792e-09), TensorBase(0.0010), TensorBase(4.6800e-09), TensorBase(5.7003e-06), TensorBase(0.2044), TensorBase(2.1475e-07), TensorBase(3.7607e-08), TensorBase(1.8063e-07), TensorBase(0.0025), TensorBase(3.9478e-07), TensorBase(5.6565e-09), TensorBase(2.0036e-07), TensorBase(4.9652e-08), TensorBase(9.1455e-07), TensorBase(3.8791e-06), TensorBase(1.6842e-06), TensorBase(2.3038e-06), TensorBase(0.0002), Tensor...\n",
       "4793    (virabhadrasana iii, TensorBase(102), [TensorBase(8.6332e-08), TensorBase(7.5092e-09), TensorBase(1.6425e-11), TensorBase(7.9704e-13), TensorBase(8.2099e-11), TensorBase(5.1168e-10), TensorBase(1.4432e-11), TensorBase(1.9392e-05), TensorBase(2.2679e-14), TensorBase(2.8717e-10), TensorBase(1.9294e-07), TensorBase(6.4091e-10), TensorBase(2.6088e-10), TensorBase(7.2822e-12), TensorBase(1.3363e-07), TensorBase(7.9979e-13), TensorBase(3.5490e-11), TensorBase(4.5967e-14), TensorBase(2.3255e-12), TensorBase(1.1676e-10), TensorBase(1.2627e-10), TensorBase(3.0040e-09), TensorBase(1.4267e-06), Tenso...\n",
       "4794    (ardha matsyendrasana, TensorBase(8), [TensorBase(2.0292e-05), TensorBase(4.6050e-07), TensorBase(0.0003), TensorBase(7.5605e-08), TensorBase(7.6230e-07), TensorBase(3.4181e-05), TensorBase(9.5694e-05), TensorBase(9.6411e-08), TensorBase(0.9788), TensorBase(1.6163e-06), TensorBase(2.7134e-08), TensorBase(1.4191e-06), TensorBase(1.1821e-06), TensorBase(5.5916e-06), TensorBase(8.1089e-08), TensorBase(1.1184e-06), TensorBase(5.4806e-06), TensorBase(0.0119), TensorBase(7.0222e-07), TensorBase(3.3991e-05), TensorBase(2.9073e-06), TensorBase(9.2210e-08), TensorBase(6.7133e-06), TensorBase(1.8970...\n",
       "Name: image_path, Length: 4795, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f825b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train preds\n",
    "test_preds = test_df['image_path'].apply(lambda img:learner.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a270929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (urdhva prasarita eka padasana, TensorBase(88), [TensorBase(1.0812e-05), TensorBase(0.0302), TensorBase(5.3952e-08), TensorBase(4.9123e-07), TensorBase(5.2249e-06), TensorBase(6.1308e-06), TensorBase(2.5685e-07), TensorBase(5.5477e-05), TensorBase(3.0729e-08), TensorBase(4.3842e-05), TensorBase(1.9795e-05), TensorBase(1.7202e-07), TensorBase(3.7454e-07), TensorBase(5.4758e-08), TensorBase(5.5241e-05), TensorBase(6.9351e-06), TensorBase(2.2164e-05), TensorBase(1.4209e-07), TensorBase(1.7535e-06), TensorBase(4.1362e-06), TensorBase(2.8964e-05), TensorBase(4.1741e-08), TensorBase(1.2565e-06),...\n",
       "1       (eka pada koundinyanasana ii, TensorBase(30), [TensorBase(1.0119e-05), TensorBase(0.0007), TensorBase(9.7801e-06), TensorBase(1.0161e-05), TensorBase(0.0004), TensorBase(0.0001), TensorBase(3.0739e-05), TensorBase(0.0007), TensorBase(2.0471e-05), TensorBase(0.0029), TensorBase(3.5147e-05), TensorBase(0.0006), TensorBase(0.0040), TensorBase(0.0003), TensorBase(0.0040), TensorBase(1.2698e-05), TensorBase(4.2232e-05), TensorBase(3.8974e-06), TensorBase(0.0006), TensorBase(1.0833e-06), TensorBase(0.0003), TensorBase(5.4488e-06), TensorBase(0.0003), TensorBase(4.7646e-06), TensorBase(0.0013), T...\n",
       "2       (anantasana, TensorBase(4), [TensorBase(8.9259e-07), TensorBase(9.2086e-06), TensorBase(3.2897e-06), TensorBase(4.6088e-05), TensorBase(0.8538), TensorBase(1.2721e-05), TensorBase(2.5966e-06), TensorBase(7.7530e-05), TensorBase(8.2320e-08), TensorBase(8.6244e-06), TensorBase(1.2168e-07), TensorBase(8.9327e-08), TensorBase(4.2426e-07), TensorBase(5.9616e-06), TensorBase(3.7041e-08), TensorBase(0.0002), TensorBase(7.0751e-05), TensorBase(1.7935e-06), TensorBase(7.4643e-06), TensorBase(4.6481e-05), TensorBase(1.6954e-08), TensorBase(4.1577e-07), TensorBase(1.4426e-07), TensorBase(5.8301e-08),...\n",
       "3       (ardha matsyendrasana, TensorBase(8), [TensorBase(0.0011), TensorBase(4.1171e-06), TensorBase(0.0003), TensorBase(5.0181e-05), TensorBase(6.5441e-07), TensorBase(0.0002), TensorBase(6.9302e-06), TensorBase(1.1777e-05), TensorBase(0.5123), TensorBase(0.0001), TensorBase(0.0008), TensorBase(0.0004), TensorBase(3.1235e-06), TensorBase(0.0013), TensorBase(3.1406e-05), TensorBase(8.1439e-05), TensorBase(6.1543e-05), TensorBase(0.0365), TensorBase(3.4358e-05), TensorBase(2.5663e-06), TensorBase(0.0030), TensorBase(0.0003), TensorBase(0.0001), TensorBase(0.0006), TensorBase(7.0074e-06), TensorBas...\n",
       "4       (gomukhasana, TensorBase(36), [TensorBase(2.1454e-08), TensorBase(8.2650e-08), TensorBase(0.0002), TensorBase(5.7069e-09), TensorBase(5.3856e-10), TensorBase(2.4659e-06), TensorBase(1.1138e-09), TensorBase(1.0922e-09), TensorBase(2.0825e-06), TensorBase(7.7052e-09), TensorBase(1.3901e-08), TensorBase(2.8389e-07), TensorBase(4.2742e-09), TensorBase(6.8864e-07), TensorBase(5.7186e-09), TensorBase(3.2055e-08), TensorBase(2.3931e-10), TensorBase(5.4776e-05), TensorBase(7.5189e-10), TensorBase(1.0493e-07), TensorBase(6.3083e-10), TensorBase(4.7368e-08), TensorBase(4.3337e-10), TensorBase(6.1842...\n",
       "                                                                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                                                                           \n",
       "1194    (utthita parsvakonasana, TensorBase(95), [TensorBase(9.2529e-09), TensorBase(8.8293e-10), TensorBase(1.8518e-09), TensorBase(1.4186e-09), TensorBase(1.7294e-05), TensorBase(6.4933e-09), TensorBase(4.6401e-07), TensorBase(4.3456e-08), TensorBase(7.0311e-08), TensorBase(4.0769e-09), TensorBase(7.3993e-11), TensorBase(1.6184e-11), TensorBase(4.3612e-06), TensorBase(2.1565e-10), TensorBase(1.0348e-08), TensorBase(1.8587e-08), TensorBase(0.0008), TensorBase(6.1520e-09), TensorBase(5.9620e-09), TensorBase(8.7175e-09), TensorBase(1.6860e-08), TensorBase(6.5212e-10), TensorBase(6.9495e-07), Tensor...\n",
       "1195    (bakasana, TensorBase(14), [TensorBase(1.4931e-08), TensorBase(5.6183e-09), TensorBase(5.9415e-13), TensorBase(6.1370e-14), TensorBase(4.8807e-13), TensorBase(2.3879e-12), TensorBase(5.8801e-13), TensorBase(1.0571e-07), TensorBase(8.2332e-14), TensorBase(1.8726e-07), TensorBase(2.8024e-06), TensorBase(4.9562e-10), TensorBase(4.9197e-11), TensorBase(5.8458e-11), TensorBase(0.9995), TensorBase(5.3144e-11), TensorBase(3.3007e-13), TensorBase(2.0583e-13), TensorBase(2.4613e-12), TensorBase(1.2513e-12), TensorBase(1.1308e-08), TensorBase(1.9782e-10), TensorBase(2.1929e-09), TensorBase(6.1880e-0...\n",
       "1196    (chakravakasana, TensorBase(23), [TensorBase(1.4372e-06), TensorBase(1.8639e-08), TensorBase(9.6158e-08), TensorBase(3.6357e-07), TensorBase(1.5562e-07), TensorBase(0.0003), TensorBase(9.2519e-07), TensorBase(5.5331e-06), TensorBase(1.4699e-06), TensorBase(9.7643e-06), TensorBase(2.5016e-05), TensorBase(1.3623e-05), TensorBase(1.2995e-07), TensorBase(6.1976e-07), TensorBase(2.5979e-06), TensorBase(2.8758e-08), TensorBase(6.4153e-08), TensorBase(2.6846e-07), TensorBase(3.3967e-07), TensorBase(4.0924e-05), TensorBase(3.8620e-07), TensorBase(0.4730), TensorBase(8.7772e-07), TensorBase(0.5056)...\n",
       "1197    (utthita trikonasana, TensorBase(96), [TensorBase(0.0015), TensorBase(1.4296e-08), TensorBase(4.0449e-08), TensorBase(3.8543e-07), TensorBase(1.7787e-06), TensorBase(2.2782e-06), TensorBase(2.0979e-07), TensorBase(9.8647e-06), TensorBase(9.6799e-05), TensorBase(1.7231e-05), TensorBase(6.6686e-07), TensorBase(2.2419e-07), TensorBase(4.1650e-07), TensorBase(4.1476e-07), TensorBase(1.3996e-07), TensorBase(1.9183e-08), TensorBase(5.0969e-06), TensorBase(6.1405e-07), TensorBase(6.8810e-08), TensorBase(1.5136e-08), TensorBase(6.8763e-06), TensorBase(5.6554e-08), TensorBase(4.4037e-05), TensorBas...\n",
       "1198    (parsva bakasana, TensorBase(60), [TensorBase(2.3054e-06), TensorBase(0.0002), TensorBase(1.6948e-07), TensorBase(2.4608e-07), TensorBase(6.3822e-07), TensorBase(4.1214e-07), TensorBase(5.3202e-06), TensorBase(2.4332e-05), TensorBase(1.5722e-07), TensorBase(5.8723e-06), TensorBase(1.3097e-05), TensorBase(1.3363e-05), TensorBase(0.0036), TensorBase(2.5998e-06), TensorBase(0.0229), TensorBase(1.0389e-07), TensorBase(0.0001), TensorBase(1.7712e-07), TensorBase(6.4873e-06), TensorBase(2.6986e-07), TensorBase(0.0072), TensorBase(2.9168e-06), TensorBase(0.0001), TensorBase(5.5352e-05), TensorBas...\n",
       "Name: image_path, Length: 1199, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa653e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
